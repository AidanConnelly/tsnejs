{"version":3,"sources":["webpack:///bundle.min.js","webpack:///webpack/bootstrap 3a1838d14c2ef7502576","webpack:///./dist/index.js","webpack:///./lib/index.js"],"names":["modules","__webpack_require__","moduleId","installedModules","exports","module","id","loaded","call","m","c","p","window","tsnejs","_classCallCheck","instance","Constructor","TypeError","sign","x","Object","defineProperty","value","_createClass","defineProperties","target","props","i","length","descriptor","enumerable","configurable","writable","key","protoProps","staticProps","prototype","assert","condition","message","getopt","opt","field","defaultval","hasOwnProperty","return_v","v_val","gaussRandom","u","Math","random","v","r","sqrt","log","randn","mu","std","zeros","n","isNaN","ArrayBuffer","arr","Array","Float64Array","randn2d","d","s","uses","xhere","j","push","L2","x1","x2","D","x1i","x2i","xtod","X","N","dist","d2p","perplexity","tol","Nf","floor","Htarget","P","prow","betamin","Infinity","betamax","beta","done","maxtries","num","psum","pj","exp","Hhere","abs","Pout","N2","max","tSNE","arguments","undefined","this","dim","epsilon","iter","dists","initSolution","Y","gains","ystep","cg","costGrad","cost","grad","ymean","gid","sid","gainid","newgain","momval","newsid","e","yold","cg0","cg1","analytic","numerical","console","pmul","Qu","qsum","dsum","dhere","qu","NN","Q","q","gsum","premult"],"mappings":";CAAS,SAAUA,GCInB,QAAAC,GAAAC,GAGA,GAAAC,EAAAD,GACA,MAAAC,GAAAD,GAAAE,OAGA,IAAAC,GAAAF,EAAAD,IACAE,WACAE,GAAAJ,EACAK,QAAA,EAUA,OANAP,GAAAE,GAAAM,KAAAH,EAAAD,QAAAC,IAAAD,QAAAH,GAGAI,EAAAE,QAAA,EAGAF,EAAAD,QAvBA,GAAAD,KAqCA,OATAF,GAAAQ,EAAAT,EAGAC,EAAAS,EAAAP,EAGAF,EAAAU,EAAA,GAGAV,EAAA,KDMM,SAASI,EAAQD,EAASH,GE5ChCW,OAAAC,OAAAZ,EAAA,IFmDM,SAASI,EAAQD,GGnDvB,YAUA,SAAAU,GAAAC,EAAAC,GAAiD,KAAAD,YAAAC,IAA0C,SAAAC,WAAA,qCAsN3F,QAAAC,GAAAC,GACA,MAAAA,GAAA,IAAAA,EAAA,OA/NAC,OAAAC,eAAAjB,EAAA,cACAkB,OAAA,GAGA,IAAAC,GAAA,WAAgC,QAAAC,GAAAC,EAAAC,GAA2C,OAAAC,GAAA,EAAgBA,EAAAD,EAAAE,OAAkBD,IAAA,CAAO,GAAAE,GAAAH,EAAAC,EAA2BE,GAAAC,WAAAD,EAAAC,aAAA,EAAwDD,EAAAE,cAAA,EAAgC,SAAAF,OAAAG,UAAA,GAAuDZ,OAAAC,eAAAI,EAAAI,EAAAI,IAAAJ,IAA+D,gBAAAb,EAAAkB,EAAAC,GAA2L,MAAlID,IAAAV,EAAAR,EAAAoB,UAAAF,GAAqEC,GAAAX,EAAAR,EAAAmB,GAA6DnB,KAExhBZ,GAAAc,MAIA,IAAAmB,GAAA,SAAAC,EAAAC,GACA,IAAAD,EACA,KAAAC,IAAA,oBAOAC,EAAA,SAAAC,EAAAC,EAAAC,GACA,MAAAF,GAAAG,eAAAF,GACAD,EAAAC,GAEAC,GAOAE,GAAA,EACAC,EAAA,EACAC,EAAA3C,EAAA2C,YAAA,QAAAA,KACA,GAAAF,EAEA,MADAA,IAAA,EACAC,CAEA,IAAAE,GAAA,EAAAC,KAAAC,SAAA,EACAC,EAAA,EAAAF,KAAAC,SAAA,EACAE,EAAAJ,IAAAG,GACA,OAAAC,KAAA,QAAAL,IACA,IAAArC,GAAAuC,KAAAI,MAAA,EAAAJ,KAAAK,IAAAF,KAGA,OAFAN,GAAAK,EAAAzC,EACAmC,GAAA,EACAG,EAAAtC,GAMA6C,EAAAnD,EAAAmD,MAAA,SAAAC,EAAAC,GACA,MAAAD,GAAAT,IAAAU,GAMAC,EAAA,SAAAC,GACA,sBAAAA,IAAAC,MAAAD,GACA,QAEA,uBAAAE,aAAA,CAGA,OADAC,GAAA,GAAAC,OAAAJ,GACAhC,EAAA,EAAmBA,EAAAgC,EAAOhC,IAC1BmC,EAAAnC,GAAA,CAEA,OAAAmC,GAEA,UAAAE,cAAAL,IAQAM,EAAA7D,EAAA6D,QAAA,SAAAN,EAAAO,EAAAC,GAGA,OAFAC,GAAA,mBAAAD,GACAhD,KACAQ,EAAA,EAAiBA,EAAAgC,EAAOhC,IAAA,CAExB,OADA0C,MACAC,EAAA,EAAmBA,EAAAJ,EAAOI,IAC1BF,EACAC,EAAAE,KAAAJ,GAEAE,EAAAE,KAAAhB,EAAA,QAGApC,GAAAoD,KAAAF,GAEA,MAAAlD,IAMAqD,EAAApE,EAAAoE,GAAA,SAAAC,EAAAC,GAGA,OAFAC,GAAAF,EAAA7C,OACAsC,EAAA,EACAvC,EAAA,EAAiBA,EAAAgD,EAAOhD,IAAA,CACxB,GAAAiD,GAAAH,EAAA9C,GACAkD,EAAAH,EAAA/C,EACAuC,KAAAU,EAAAC,IAAAD,EAAAC,GAEA,MAAAX,IAMAY,EAAA1E,EAAA0E,KAAA,SAAAC,GAGA,OAFAC,GAAAD,EAAAnD,OACAqD,EAAAvB,EAAAsB,KACArD,EAAA,EAAiBA,EAAAqD,EAAOrD,IACxB,OAAA2C,GAAA3C,EAAA,EAAuB2C,EAAAU,EAAOV,IAAA,CAC9B,GAAAJ,GAAAM,EAAAO,EAAApD,GAAAoD,EAAAT,GACAW,GAAAtD,EAAAqD,EAAAV,GAAAJ,EACAe,EAAAX,EAAAU,EAAArD,GAAAuC,EAGA,MAAAe,IAMAC,EAAA9E,EAAA8E,IAAA,SAAAP,EAAAQ,EAAAC,GACA,GAAAC,GAAApC,KAAAI,KAAAsB,EAAA/C,QACAoD,EAAA/B,KAAAqC,MAAAD,EACAhD,GAAA2C,IAAAK,EAAA,2CAKA,QAJAE,GAAAtC,KAAAK,IAAA6B,GACAK,EAAA9B,EAAAsB,KAEAS,EAAA/B,EAAAsB,GACArD,EAAA,EAAiBA,EAAAqD,EAAOrD,IAAA,CAUxB,IATA,GAAA+D,KAAAC,KACAC,EAAAD,IACAE,EAAA,EACAC,GAAA,EACAC,EAAA,GAIAC,EAAA,GACAF,GAAA,CAKA,OADAG,GAAA,EACA3B,EAAA,EAAqBA,EAAAU,EAAOV,IAAA,CAC5B,GAAA4B,GAAAjD,KAAAkD,KAAAxB,EAAAhD,EAAAqD,EAAAV,GAAAuB,EACAlE,KAAA2C,IACA4B,EAAA,GAEAT,EAAAnB,GAAA4B,EACAD,GAAAC,EAIA,OADAE,GAAA,EACA9B,EAAA,EAAqBA,EAAAU,EAAOV,IAAA,CAC5B,MAAA2B,EACA,GAAAC,GAAA,MAEA,IAAAA,GAAAT,EAAAnB,GAAA2B,CAEAR,GAAAnB,GAAA4B,EACAA,EAAA,OAAAE,GAAAF,EAAAjD,KAAAK,IAAA4C,IAIAE,EAAAb,GAGAG,EAAAG,EACAD,IAAAD,IACAE,GAAA,EAEAA,KAAAD,GAAA,IAIAA,EAAAC,EACAH,MAAAC,KACAE,GAAA,EAEAA,KAAAH,GAAA,GAKAM,IACA/C,KAAAoD,IAAAD,EAAAb,GAAAH,IACAU,GAAA,GAEAE,GAAAD,IACAD,GAAA,GAMA,OAAAxB,GAAA,EAAmBA,EAAAU,EAAOV,IAC1BkB,EAAA7D,EAAAqD,EAAAV,GAAAmB,EAAAnB,GAOA,OAFAgC,GAAA5C,EAAAsB,KACAuB,EAAA,EAAAvB,EACArD,EAAA,EAAiBA,EAAAqD,EAAOrD,IACxB,OAAA2C,GAAA,EAAmBA,EAAAU,EAAOV,IAC1BgC,EAAA3E,EAAAqD,EAAAV,GAAArB,KAAAuD,KAAAhB,EAAA7D,EAAAqD,EAAAV,GAAAkB,EAAAlB,EAAAU,EAAArD,IAAA4E,EAAA,OAIA,OAAAD,GAcAlG,GAAAqG,KAAA,WACA,QAAAA,KACA,GAAAhE,GAAAiE,UAAA9E,OAAA,GAAA+E,SAAAD,UAAA,GAAAA,UAAA,KAEA5F,GAAA8F,KAAAH,GAEAG,KAAAzB,WAAA3C,EAAAC,EAAA,iBACAmE,KAAAC,IAAArE,EAAAC,EAAA,SACAmE,KAAAE,QAAAtE,EAAAC,EAAA,cACAmE,KAAAG,KAAA,EAqMA,MA9LAxF,GAAAkF,IACAxE,IAAA,cACAX,MAAA,SAAAyD,GACA,GAAAC,GAAAD,EAAAnD,OACA+C,EAAAI,EAAA,GAAAnD,MACAS,GAAA2C,EAAA,2CACA3C,EAAAsC,EAAA,uCACA,IAAAqC,GAAAlC,EAAAC,EACA6B,MAAApB,EAAAN,EAAA8B,EAAAJ,KAAAzB,WAAA,MACAyB,KAAA5B,IACA4B,KAAAK,kBAQAhF,IAAA,eACAX,MAAA,SAAAqD,GACA,GAAAK,GAAAL,EAAA/C,MACAS,GAAA2C,EAAA,0CAGA,QADAgC,GAAAtD,EAAAsB,KACArD,EAAA,EAAqBA,EAAAqD,EAAOrD,IAC5B,OAAA2C,GAAA3C,EAAA,EAA2B2C,EAAAU,EAAOV,IAAA,CAClC,GAAAJ,GAAAS,EAAAhD,GAAA2C,EACA0C,GAAArF,EAAAqD,EAAAV,GAAAJ,EACA8C,EAAA1C,EAAAU,EAAArD,GAAAuC,EAGA0C,KAAApB,EAAAN,EAAA8B,EAAAJ,KAAAzB,WAAA,MACAyB,KAAA5B,IACA4B,KAAAK,kBAMAhF,IAAA,eACAX,MAAA,WAEAsF,KAAAM,EAAAjD,EAAA2C,KAAA5B,EAAA4B,KAAAC,KACAD,KAAAO,MAAAlD,EAAA2C,KAAA5B,EAAA4B,KAAAC,IAAA,GACAD,KAAAQ,MAAAnD,EAAA2C,KAAA5B,EAAA4B,KAAAC,IAAA,GACAD,KAAAG,KAAA,KAMA9E,IAAA,cACAX,MAAA,WACA,MAAAsF,MAAAM,KAMAjF,IAAA,OACAX,MAAA,WACAsF,KAAAG,MAAA,CASA,QARA/B,GAAA4B,KAAA5B,EAEAqC,EAAAT,KAAAU,SAAAV,KAAAM,GACAK,EAAAF,EAAAE,KACAC,EAAAH,EAAAG,KAGAC,EAAA/D,EAAAkD,KAAAC,KACAlF,EAAA,EAAqBA,EAAAqD,EAAOrD,IAC5B,OAAAuC,GAAA,EAAuBA,EAAA0C,KAAAC,IAAc3C,IAAA,CACrC,GAAAwD,GAAAF,EAAA7F,GAAAuC,GACAyD,EAAAf,KAAAQ,MAAAzF,GAAAuC,GACA0D,EAAAhB,KAAAO,MAAAxF,GAAAuC,GAGA2D,EAAA3G,EAAAwG,KAAAxG,EAAAyG,GAAA,GAAAC,IAAA,EACAC,GAAA,MAAAA,EAAA,KACAjB,KAAAO,MAAAxF,GAAAuC,GAAA2D,CAGA,IAAAC,GAAAlB,KAAAG,KAAA,UACAgB,EAAAD,EAAAH,EAAAf,KAAAE,QAAAe,EAAAL,EAAA7F,GAAAuC,EACA0C,MAAAQ,MAAAzF,GAAAuC,GAAA6D,EAGAnB,KAAAM,EAAAvF,GAAAuC,IAAA6D,EAEAN,EAAAvD,IAAA0C,KAAAM,EAAAvF,GAAAuC,GAKA,OAAAvC,GAAA,EAAqBA,EAAAqD,EAAOrD,IAC5B,OAAAuC,GAAA,EAAuBA,EAAA0C,KAAAC,IAAc3C,IACrC0C,KAAAM,EAAAvF,GAAAuC,IAAAuD,EAAAvD,GAAAc,CAKA,OAAAuC,MAMAtF,IAAA,YACAX,MAAA,WAQA,OAPA0D,GAAA4B,KAAA5B,EAEAqC,EAAAT,KAAAU,SAAAV,KAAAM,GAEAM,GADAH,EAAAE,KACAF,EAAAG,MAEAQ,EAAA,KACArG,EAAA,EAAqBA,EAAAqD,EAAOrD,IAC5B,OAAAuC,GAAA,EAAuBA,EAAA0C,KAAAC,IAAc3C,IAAA,CACrC,GAAA+D,GAAArB,KAAAM,EAAAvF,GAAAuC,EAEA0C,MAAAM,EAAAvF,GAAAuC,GAAA+D,EAAAD,CACA,IAAAE,GAAAtB,KAAAU,SAAAV,KAAAM,EAEAN,MAAAM,EAAAvF,GAAAuC,GAAA+D,EAAAD,CACA,IAAAG,GAAAvB,KAAAU,SAAAV,KAAAM,GAEAkB,EAAAZ,EAAA7F,GAAAuC,GACAmE,GAAAH,EAAAX,KAAAY,EAAAZ,OAAA,EAAAS,EACAM,SAAAhF,IAAA3B,EAAA,IAAAuC,EAAA,yBAAAkE,EAAA,mBAAAC,GAEAzB,KAAAM,EAAAvF,GAAAuC,GAAA+D,MAQAhG,IAAA,WACAX,MAAA,SAAA4F,GAUA,OATAlC,GAAA4B,KAAA5B,EACA6B,EAAAD,KAAAC,IACArB,EAAAoB,KAAApB,EAEA+C,EAAA3B,KAAAG,KAAA,QAGAyB,EAAA9E,EAAAsB,KACAyD,EAAA,EACA9G,EAAA,EAAqBA,EAAAqD,EAAOrD,IAC5B,OAAA2C,GAAA3C,EAAA,EAA2B2C,EAAAU,EAAOV,IAAA,CAElC,OADAoE,GAAA,EACAxE,EAAA,EAAyBA,EAAA2C,EAAS3C,IAAA,CAClC,GAAAyE,GAAAzB,EAAAvF,GAAAuC,GAAAgD,EAAA5C,GAAAJ,EACAwE,IAAAC,IAEA,GAAAC,GAAA,KAAAF,EACAF,GAAA7G,EAAAqD,EAAAV,GAAAsE,EACAJ,EAAAlE,EAAAU,EAAArD,GAAAiH,EACAH,GAAA,EAAAG,EAMA,OAFAC,GAAA7D,IACA8D,EAAApF,EAAAmF,GACAE,EAAA,EAAqBA,EAAAF,EAAQE,IAC7BD,EAAAC,GAAA9F,KAAAuD,IAAAgC,EAAAO,GAAAN,EAAA,OAKA,QAFAlB,GAAA,EACAC,KACA7F,EAAA,EAAqBA,EAAAqD,EAAOrD,IAAA,CAE5B,OADAqH,GAAA,GAAAjF,OAAA8C,GACA3C,EAAA,EAAuBA,EAAA2C,EAAS3C,IAChC8E,EAAA9E,GAAA,CAEA,QAAAI,GAAA,EAAuBA,EAAAU,EAAOV,IAAA,CAC9BiD,IAAA/B,EAAA7D,EAAAqD,EAAAV,GAAArB,KAAAK,IAAAwF,EAAAnH,EAAAqD,EAAAV,GAEA,QADA2E,GAAA,GAAAV,EAAA/C,EAAA7D,EAAAqD,EAAAV,GAAAwE,EAAAnH,EAAAqD,EAAAV,IAAAkE,EAAA7G,EAAAqD,EAAAV,GACAJ,EAAA,EAAyBA,EAAA2C,EAAS3C,IAClC8E,EAAA9E,IAAA+E,GAAA/B,EAAAvF,GAAAuC,GAAAgD,EAAA5C,GAAAJ,IAGAsD,EAAAjD,KAAAyE,GAGA,OAAczB,OAAAC,YAIdf","file":"bundle.min.js","sourcesContent":["/******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId])\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\texports: {},\n/******/ \t\t\tid: moduleId,\n/******/ \t\t\tloaded: false\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.loaded = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"\";\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(0);\n/******/ })\n/************************************************************************/\n/******/ ([\n/* 0 */\n/***/ function(module, exports, __webpack_require__) {\n\n\twindow.tsnejs = __webpack_require__(1);\n\n\n/***/ },\n/* 1 */\n/***/ function(module, exports) {\n\n\t'use strict';\n\t\n\tObject.defineProperty(exports, \"__esModule\", {\n\t  value: true\n\t});\n\t\n\tvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\t\n\texports.sign = sign;\n\t\n\tfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\t\n\tvar assert = function assert(condition, message) {\n\t  if (!condition) {\n\t    throw message || \"Assertion failed\";\n\t  }\n\t};\n\t\n\t/**\n\t * syntax sugar\n\t */\n\tvar getopt = function getopt(opt, field, defaultval) {\n\t  if (opt.hasOwnProperty(field)) {\n\t    return opt[field];\n\t  } else {\n\t    return defaultval;\n\t  }\n\t};\n\t\n\t/**\n\t * return 0 mean unit standard deviation random number\n\t */\n\tvar return_v = false;\n\tvar v_val = 0.0;\n\tvar gaussRandom = exports.gaussRandom = function gaussRandom() {\n\t  if (return_v) {\n\t    return_v = false;\n\t    return v_val;\n\t  }\n\t  var u = 2 * Math.random() - 1;\n\t  var v = 2 * Math.random() - 1;\n\t  var r = u * u + v * v;\n\t  if (r == 0 || r > 1) return gaussRandom();\n\t  var c = Math.sqrt(-2 * Math.log(r) / r);\n\t  v_val = v * c; // cache this for next function call for efficiency\n\t  return_v = true;\n\t  return u * c;\n\t};\n\t\n\t/**\n\t * return random normal number\n\t */\n\tvar randn = exports.randn = function randn(mu, std) {\n\t  return mu + gaussRandom() * std;\n\t};\n\t\n\t/**\n\t * utilitity that creates contiguous vector of zeros of size n\n\t */\n\tvar zeros = function zeros(n) {\n\t  if (typeof n === 'undefined' || isNaN(n)) {\n\t    return [];\n\t  }\n\t  if (typeof ArrayBuffer === 'undefined') {\n\t    // lacking browser support\n\t    var arr = new Array(n);\n\t    for (var i = 0; i < n; i++) {\n\t      arr[i] = 0;\n\t    }\n\t    return arr;\n\t  } else {\n\t    return new Float64Array(n); // typed arrays are faster\n\t  }\n\t};\n\t\n\t/**\n\t *  utility that returns 2d array filled with random numbers\n\t * or with value s, if provided\n\t */\n\tvar randn2d = exports.randn2d = function randn2d(n, d, s) {\n\t  var uses = typeof s !== 'undefined';\n\t  var x = [];\n\t  for (var i = 0; i < n; i++) {\n\t    var xhere = [];\n\t    for (var j = 0; j < d; j++) {\n\t      if (uses) {\n\t        xhere.push(s);\n\t      } else {\n\t        xhere.push(randn(0.0, 1e-4));\n\t      }\n\t    }\n\t    x.push(xhere);\n\t  }\n\t  return x;\n\t};\n\t\n\t/**\n\t * compute L2 distance between two vectors\n\t */\n\tvar L2 = exports.L2 = function L2(x1, x2) {\n\t  var D = x1.length;\n\t  var d = 0;\n\t  for (var i = 0; i < D; i++) {\n\t    var x1i = x1[i];\n\t    var x2i = x2[i];\n\t    d += (x1i - x2i) * (x1i - x2i);\n\t  }\n\t  return d;\n\t};\n\t\n\t/**\n\t * compute pairwise distance in all vectors in X\n\t */\n\tvar xtod = exports.xtod = function xtod(X) {\n\t  var N = X.length;\n\t  var dist = zeros(N * N); // allocate contiguous array\n\t  for (var i = 0; i < N; i++) {\n\t    for (var j = i + 1; j < N; j++) {\n\t      var d = L2(X[i], X[j]);\n\t      dist[i * N + j] = d;\n\t      dist[j * N + i] = d;\n\t    }\n\t  }\n\t  return dist;\n\t};\n\t\n\t/**\n\t * compute (p_{i|j} + p_{j|i})/(2n)\n\t */\n\tvar d2p = exports.d2p = function d2p(D, perplexity, tol) {\n\t  var Nf = Math.sqrt(D.length); // this better be an integer\n\t  var N = Math.floor(Nf);\n\t  assert(N === Nf, \"D should have square number of elements.\");\n\t  var Htarget = Math.log(perplexity); // target entropy of distribution\n\t  var P = zeros(N * N); // temporary probability matrix\n\t\n\t  var prow = zeros(N); // a temporary storage compartment\n\t  for (var i = 0; i < N; i++) {\n\t    var betamin = -Infinity;\n\t    var betamax = Infinity;\n\t    var beta = 1; // initial value of precision\n\t    var done = false;\n\t    var maxtries = 50;\n\t\n\t    // perform binary search to find a suitable precision beta\n\t    // so that the entropy of the distribution is appropriate\n\t    var num = 0;\n\t    while (!done) {\n\t      //debugger;\n\t\n\t      // compute entropy and kernel row with beta precision\n\t      var psum = 0.0;\n\t      for (var j = 0; j < N; j++) {\n\t        var pj = Math.exp(-D[i * N + j] * beta);\n\t        if (i === j) {\n\t          pj = 0;\n\t        } // we dont care about diagonals\n\t        prow[j] = pj;\n\t        psum += pj;\n\t      }\n\t      // normalize p and compute entropy\n\t      var Hhere = 0.0;\n\t      for (var j = 0; j < N; j++) {\n\t        if (psum == 0) {\n\t          var pj = 0;\n\t        } else {\n\t          var pj = prow[j] / psum;\n\t        }\n\t        prow[j] = pj;\n\t        if (pj > 1e-7) Hhere -= pj * Math.log(pj);\n\t      }\n\t\n\t      // adjust beta based on result\n\t      if (Hhere > Htarget) {\n\t        // entropy was too high (distribution too diffuse)\n\t        // so we need to increase the precision for more peaky distribution\n\t        betamin = beta; // move up the bounds\n\t        if (betamax === Infinity) {\n\t          beta = beta * 2;\n\t        } else {\n\t          beta = (beta + betamax) / 2;\n\t        }\n\t      } else {\n\t        // converse case. make distrubtion less peaky\n\t        betamax = beta;\n\t        if (betamin === -Infinity) {\n\t          beta = beta / 2;\n\t        } else {\n\t          beta = (beta + betamin) / 2;\n\t        }\n\t      }\n\t\n\t      // stopping conditions: too many tries or got a good precision\n\t      num++;\n\t      if (Math.abs(Hhere - Htarget) < tol) {\n\t        done = true;\n\t      }\n\t      if (num >= maxtries) {\n\t        done = true;\n\t      }\n\t    }\n\t\n\t    // console.log('data point ' + i + ' gets precision ' + beta + ' after ' + num + ' binary search steps.');\n\t    // copy over the final prow to P at row i\n\t    for (var j = 0; j < N; j++) {\n\t      P[i * N + j] = prow[j];\n\t    }\n\t  } // end loop over examples i\n\t\n\t  // symmetrize P and normalize it to sum to 1 over all ij\n\t  var Pout = zeros(N * N);\n\t  var N2 = N * 2;\n\t  for (var i = 0; i < N; i++) {\n\t    for (var j = 0; j < N; j++) {\n\t      Pout[i * N + j] = Math.max((P[i * N + j] + P[j * N + i]) / N2, 1e-100);\n\t    }\n\t  }\n\t\n\t  return Pout;\n\t};\n\t\n\t/**\n\t * helper function\n\t */\n\tfunction sign(x) {\n\t  return x > 0 ? 1 : x < 0 ? -1 : 0;\n\t}\n\t\n\t/**\n\t * t-SNE visualization algorithm\n\t */\n\t\n\tvar tSNE = exports.tSNE = function () {\n\t  function tSNE() {\n\t    var opt = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\t\n\t    _classCallCheck(this, tSNE);\n\t\n\t    this.perplexity = getopt(opt, \"perplexity\", 30); // effective number of nearest neighbors\n\t    this.dim = getopt(opt, \"dim\", 2); // by default 2-D tSNE\n\t    this.epsilon = getopt(opt, \"epsilon\", 10); // learning rate\n\t    this.iter = 0;\n\t  }\n\t\n\t  // this function takes a set of high-dimensional points\n\t  // and creates matrix P from them using gaussian kernel\n\t\n\t\n\t  _createClass(tSNE, [{\n\t    key: 'initDataRaw',\n\t    value: function initDataRaw(X) {\n\t      var N = X.length;\n\t      var D = X[0].length;\n\t      assert(N > 0, \" X is empty? You must have some data!\");\n\t      assert(D > 0, \" X[0] is empty? Where is the data?\");\n\t      var dists = xtod(X); // convert X to distances using gaussian kernel\n\t      this.P = d2p(dists, this.perplexity, 1e-4); // attach to object\n\t      this.N = N; // back up the size of the dataset\n\t      this.initSolution(); // refresh this\n\t    }\n\t\n\t    // this function takes a given distance matrix and creates\n\t    // matrix P from them.\n\t    // D is assumed to be provided as a list of lists, and should be symmetric\n\t\n\t  }, {\n\t    key: 'initDataDist',\n\t    value: function initDataDist(D) {\n\t      var N = D.length;\n\t      assert(N > 0, \" X is empty? You must have some data!\");\n\t      // convert D to a (fast) typed array version\n\t      var dists = zeros(N * N); // allocate contiguous array\n\t      for (var i = 0; i < N; i++) {\n\t        for (var j = i + 1; j < N; j++) {\n\t          var d = D[i][j];\n\t          dists[i * N + j] = d;\n\t          dists[j * N + i] = d;\n\t        }\n\t      }\n\t      this.P = d2p(dists, this.perplexity, 1e-4);\n\t      this.N = N;\n\t      this.initSolution(); // refresh this\n\t    }\n\t\n\t    // (re)initializes the solution to random\n\t\n\t  }, {\n\t    key: 'initSolution',\n\t    value: function initSolution() {\n\t      // generate random solution to t-SNE\n\t      this.Y = randn2d(this.N, this.dim); // the solution\n\t      this.gains = randn2d(this.N, this.dim, 1.0); // step gains to accelerate progress in unchanging directions\n\t      this.ystep = randn2d(this.N, this.dim, 0.0); // momentum accumulator\n\t      this.iter = 0;\n\t    }\n\t\n\t    // return pointer to current solution\n\t\n\t  }, {\n\t    key: 'getSolution',\n\t    value: function getSolution() {\n\t      return this.Y;\n\t    }\n\t\n\t    // perform a single step of optimization to improve the embedding\n\t\n\t  }, {\n\t    key: 'step',\n\t    value: function step() {\n\t      this.iter += 1;\n\t      var N = this.N;\n\t\n\t      var cg = this.costGrad(this.Y); // evaluate gradient\n\t      var cost = cg.cost;\n\t      var grad = cg.grad;\n\t\n\t      // perform gradient step\n\t      var ymean = zeros(this.dim);\n\t      for (var i = 0; i < N; i++) {\n\t        for (var d = 0; d < this.dim; d++) {\n\t          var gid = grad[i][d];\n\t          var sid = this.ystep[i][d];\n\t          var gainid = this.gains[i][d];\n\t\n\t          // compute gain update\n\t          var newgain = sign(gid) === sign(sid) ? gainid * 0.8 : gainid + 0.2;\n\t          if (newgain < 0.01) newgain = 0.01; // clamp\n\t          this.gains[i][d] = newgain; // store for next turn\n\t\n\t          // compute momentum step direction\n\t          var momval = this.iter < 250 ? 0.5 : 0.8;\n\t          var newsid = momval * sid - this.epsilon * newgain * grad[i][d];\n\t          this.ystep[i][d] = newsid; // remember the step we took\n\t\n\t          // step!\n\t          this.Y[i][d] += newsid;\n\t\n\t          ymean[d] += this.Y[i][d]; // accumulate mean so that we can center later\n\t        }\n\t      }\n\t\n\t      // reproject Y to be zero mean\n\t      for (var i = 0; i < N; i++) {\n\t        for (var d = 0; d < this.dim; d++) {\n\t          this.Y[i][d] -= ymean[d] / N;\n\t        }\n\t      }\n\t\n\t      //if(this.iter%100===0) console.log('iter ' + this.iter + ', cost: ' + cost);\n\t      return cost; // return current cost\n\t    }\n\t\n\t    // for debugging: gradient check\n\t\n\t  }, {\n\t    key: 'debugGrad',\n\t    value: function debugGrad() {\n\t      var N = this.N;\n\t\n\t      var cg = this.costGrad(this.Y); // evaluate gradient\n\t      var cost = cg.cost;\n\t      var grad = cg.grad;\n\t\n\t      var e = 1e-5;\n\t      for (var i = 0; i < N; i++) {\n\t        for (var d = 0; d < this.dim; d++) {\n\t          var yold = this.Y[i][d];\n\t\n\t          this.Y[i][d] = yold + e;\n\t          var cg0 = this.costGrad(this.Y);\n\t\n\t          this.Y[i][d] = yold - e;\n\t          var cg1 = this.costGrad(this.Y);\n\t\n\t          var analytic = grad[i][d];\n\t          var numerical = (cg0.cost - cg1.cost) / (2 * e);\n\t          console.log(i + ',' + d + ': gradcheck analytic: ' + analytic + ' vs. numerical: ' + numerical);\n\t\n\t          this.Y[i][d] = yold;\n\t        }\n\t      }\n\t    }\n\t\n\t    // return cost and gradient, given an arrangement\n\t\n\t  }, {\n\t    key: 'costGrad',\n\t    value: function costGrad(Y) {\n\t      var N = this.N;\n\t      var dim = this.dim; // dim of output space\n\t      var P = this.P;\n\t\n\t      var pmul = this.iter < 100 ? 4 : 1; // trick that helps with local optima\n\t\n\t      // compute current Q distribution, unnormalized first\n\t      var Qu = zeros(N * N);\n\t      var qsum = 0.0;\n\t      for (var i = 0; i < N; i++) {\n\t        for (var j = i + 1; j < N; j++) {\n\t          var dsum = 0.0;\n\t          for (var d = 0; d < dim; d++) {\n\t            var dhere = Y[i][d] - Y[j][d];\n\t            dsum += dhere * dhere;\n\t          }\n\t          var qu = 1.0 / (1.0 + dsum); // Student t-distribution\n\t          Qu[i * N + j] = qu;\n\t          Qu[j * N + i] = qu;\n\t          qsum += 2 * qu;\n\t        }\n\t      }\n\t      // normalize Q distribution to sum to 1\n\t      var NN = N * N;\n\t      var Q = zeros(NN);\n\t      for (var q = 0; q < NN; q++) {\n\t        Q[q] = Math.max(Qu[q] / qsum, 1e-100);\n\t      }\n\t\n\t      var cost = 0.0;\n\t      var grad = [];\n\t      for (var i = 0; i < N; i++) {\n\t        var gsum = new Array(dim); // init grad for point i\n\t        for (var d = 0; d < dim; d++) {\n\t          gsum[d] = 0.0;\n\t        }\n\t        for (var j = 0; j < N; j++) {\n\t          cost += -P[i * N + j] * Math.log(Q[i * N + j]); // accumulate cost (the non-constant portion at least...)\n\t          var premult = 4 * (pmul * P[i * N + j] - Q[i * N + j]) * Qu[i * N + j];\n\t          for (var d = 0; d < dim; d++) {\n\t            gsum[d] += premult * (Y[i][d] - Y[j][d]);\n\t          }\n\t        }\n\t        grad.push(gsum);\n\t      }\n\t\n\t      return { cost: cost, grad: grad };\n\t    }\n\t  }]);\n\t\n\t  return tSNE;\n\t}();\n\t\n\t;\n\n/***/ }\n/******/ ]);\n\n\n// WEBPACK FOOTER //\n// bundle.min.js"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId])\n \t\t\treturn installedModules[moduleId].exports;\n\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\texports: {},\n \t\t\tid: moduleId,\n \t\t\tloaded: false\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.loaded = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(0);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 3a1838d14c2ef7502576","window.tsnejs = require('../lib/index.js');\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./dist/index.js\n// module id = 0\n// module chunks = 0","'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nexports.sign = sign;\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar assert = function assert(condition, message) {\n  if (!condition) {\n    throw message || \"Assertion failed\";\n  }\n};\n\n/**\n * syntax sugar\n */\nvar getopt = function getopt(opt, field, defaultval) {\n  if (opt.hasOwnProperty(field)) {\n    return opt[field];\n  } else {\n    return defaultval;\n  }\n};\n\n/**\n * return 0 mean unit standard deviation random number\n */\nvar return_v = false;\nvar v_val = 0.0;\nvar gaussRandom = exports.gaussRandom = function gaussRandom() {\n  if (return_v) {\n    return_v = false;\n    return v_val;\n  }\n  var u = 2 * Math.random() - 1;\n  var v = 2 * Math.random() - 1;\n  var r = u * u + v * v;\n  if (r == 0 || r > 1) return gaussRandom();\n  var c = Math.sqrt(-2 * Math.log(r) / r);\n  v_val = v * c; // cache this for next function call for efficiency\n  return_v = true;\n  return u * c;\n};\n\n/**\n * return random normal number\n */\nvar randn = exports.randn = function randn(mu, std) {\n  return mu + gaussRandom() * std;\n};\n\n/**\n * utilitity that creates contiguous vector of zeros of size n\n */\nvar zeros = function zeros(n) {\n  if (typeof n === 'undefined' || isNaN(n)) {\n    return [];\n  }\n  if (typeof ArrayBuffer === 'undefined') {\n    // lacking browser support\n    var arr = new Array(n);\n    for (var i = 0; i < n; i++) {\n      arr[i] = 0;\n    }\n    return arr;\n  } else {\n    return new Float64Array(n); // typed arrays are faster\n  }\n};\n\n/**\n *  utility that returns 2d array filled with random numbers\n * or with value s, if provided\n */\nvar randn2d = exports.randn2d = function randn2d(n, d, s) {\n  var uses = typeof s !== 'undefined';\n  var x = [];\n  for (var i = 0; i < n; i++) {\n    var xhere = [];\n    for (var j = 0; j < d; j++) {\n      if (uses) {\n        xhere.push(s);\n      } else {\n        xhere.push(randn(0.0, 1e-4));\n      }\n    }\n    x.push(xhere);\n  }\n  return x;\n};\n\n/**\n * compute L2 distance between two vectors\n */\nvar L2 = exports.L2 = function L2(x1, x2) {\n  var D = x1.length;\n  var d = 0;\n  for (var i = 0; i < D; i++) {\n    var x1i = x1[i];\n    var x2i = x2[i];\n    d += (x1i - x2i) * (x1i - x2i);\n  }\n  return d;\n};\n\n/**\n * compute pairwise distance in all vectors in X\n */\nvar xtod = exports.xtod = function xtod(X) {\n  var N = X.length;\n  var dist = zeros(N * N); // allocate contiguous array\n  for (var i = 0; i < N; i++) {\n    for (var j = i + 1; j < N; j++) {\n      var d = L2(X[i], X[j]);\n      dist[i * N + j] = d;\n      dist[j * N + i] = d;\n    }\n  }\n  return dist;\n};\n\n/**\n * compute (p_{i|j} + p_{j|i})/(2n)\n */\nvar d2p = exports.d2p = function d2p(D, perplexity, tol) {\n  var Nf = Math.sqrt(D.length); // this better be an integer\n  var N = Math.floor(Nf);\n  assert(N === Nf, \"D should have square number of elements.\");\n  var Htarget = Math.log(perplexity); // target entropy of distribution\n  var P = zeros(N * N); // temporary probability matrix\n\n  var prow = zeros(N); // a temporary storage compartment\n  for (var i = 0; i < N; i++) {\n    var betamin = -Infinity;\n    var betamax = Infinity;\n    var beta = 1; // initial value of precision\n    var done = false;\n    var maxtries = 50;\n\n    // perform binary search to find a suitable precision beta\n    // so that the entropy of the distribution is appropriate\n    var num = 0;\n    while (!done) {\n      //debugger;\n\n      // compute entropy and kernel row with beta precision\n      var psum = 0.0;\n      for (var j = 0; j < N; j++) {\n        var pj = Math.exp(-D[i * N + j] * beta);\n        if (i === j) {\n          pj = 0;\n        } // we dont care about diagonals\n        prow[j] = pj;\n        psum += pj;\n      }\n      // normalize p and compute entropy\n      var Hhere = 0.0;\n      for (var j = 0; j < N; j++) {\n        if (psum == 0) {\n          var pj = 0;\n        } else {\n          var pj = prow[j] / psum;\n        }\n        prow[j] = pj;\n        if (pj > 1e-7) Hhere -= pj * Math.log(pj);\n      }\n\n      // adjust beta based on result\n      if (Hhere > Htarget) {\n        // entropy was too high (distribution too diffuse)\n        // so we need to increase the precision for more peaky distribution\n        betamin = beta; // move up the bounds\n        if (betamax === Infinity) {\n          beta = beta * 2;\n        } else {\n          beta = (beta + betamax) / 2;\n        }\n      } else {\n        // converse case. make distrubtion less peaky\n        betamax = beta;\n        if (betamin === -Infinity) {\n          beta = beta / 2;\n        } else {\n          beta = (beta + betamin) / 2;\n        }\n      }\n\n      // stopping conditions: too many tries or got a good precision\n      num++;\n      if (Math.abs(Hhere - Htarget) < tol) {\n        done = true;\n      }\n      if (num >= maxtries) {\n        done = true;\n      }\n    }\n\n    // console.log('data point ' + i + ' gets precision ' + beta + ' after ' + num + ' binary search steps.');\n    // copy over the final prow to P at row i\n    for (var j = 0; j < N; j++) {\n      P[i * N + j] = prow[j];\n    }\n  } // end loop over examples i\n\n  // symmetrize P and normalize it to sum to 1 over all ij\n  var Pout = zeros(N * N);\n  var N2 = N * 2;\n  for (var i = 0; i < N; i++) {\n    for (var j = 0; j < N; j++) {\n      Pout[i * N + j] = Math.max((P[i * N + j] + P[j * N + i]) / N2, 1e-100);\n    }\n  }\n\n  return Pout;\n};\n\n/**\n * helper function\n */\nfunction sign(x) {\n  return x > 0 ? 1 : x < 0 ? -1 : 0;\n}\n\n/**\n * t-SNE visualization algorithm\n */\n\nvar tSNE = exports.tSNE = function () {\n  function tSNE() {\n    var opt = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    _classCallCheck(this, tSNE);\n\n    this.perplexity = getopt(opt, \"perplexity\", 30); // effective number of nearest neighbors\n    this.dim = getopt(opt, \"dim\", 2); // by default 2-D tSNE\n    this.epsilon = getopt(opt, \"epsilon\", 10); // learning rate\n    this.iter = 0;\n  }\n\n  // this function takes a set of high-dimensional points\n  // and creates matrix P from them using gaussian kernel\n\n\n  _createClass(tSNE, [{\n    key: 'initDataRaw',\n    value: function initDataRaw(X) {\n      var N = X.length;\n      var D = X[0].length;\n      assert(N > 0, \" X is empty? You must have some data!\");\n      assert(D > 0, \" X[0] is empty? Where is the data?\");\n      var dists = xtod(X); // convert X to distances using gaussian kernel\n      this.P = d2p(dists, this.perplexity, 1e-4); // attach to object\n      this.N = N; // back up the size of the dataset\n      this.initSolution(); // refresh this\n    }\n\n    // this function takes a given distance matrix and creates\n    // matrix P from them.\n    // D is assumed to be provided as a list of lists, and should be symmetric\n\n  }, {\n    key: 'initDataDist',\n    value: function initDataDist(D) {\n      var N = D.length;\n      assert(N > 0, \" X is empty? You must have some data!\");\n      // convert D to a (fast) typed array version\n      var dists = zeros(N * N); // allocate contiguous array\n      for (var i = 0; i < N; i++) {\n        for (var j = i + 1; j < N; j++) {\n          var d = D[i][j];\n          dists[i * N + j] = d;\n          dists[j * N + i] = d;\n        }\n      }\n      this.P = d2p(dists, this.perplexity, 1e-4);\n      this.N = N;\n      this.initSolution(); // refresh this\n    }\n\n    // (re)initializes the solution to random\n\n  }, {\n    key: 'initSolution',\n    value: function initSolution() {\n      // generate random solution to t-SNE\n      this.Y = randn2d(this.N, this.dim); // the solution\n      this.gains = randn2d(this.N, this.dim, 1.0); // step gains to accelerate progress in unchanging directions\n      this.ystep = randn2d(this.N, this.dim, 0.0); // momentum accumulator\n      this.iter = 0;\n    }\n\n    // return pointer to current solution\n\n  }, {\n    key: 'getSolution',\n    value: function getSolution() {\n      return this.Y;\n    }\n\n    // perform a single step of optimization to improve the embedding\n\n  }, {\n    key: 'step',\n    value: function step() {\n      this.iter += 1;\n      var N = this.N;\n\n      var cg = this.costGrad(this.Y); // evaluate gradient\n      var cost = cg.cost;\n      var grad = cg.grad;\n\n      // perform gradient step\n      var ymean = zeros(this.dim);\n      for (var i = 0; i < N; i++) {\n        for (var d = 0; d < this.dim; d++) {\n          var gid = grad[i][d];\n          var sid = this.ystep[i][d];\n          var gainid = this.gains[i][d];\n\n          // compute gain update\n          var newgain = sign(gid) === sign(sid) ? gainid * 0.8 : gainid + 0.2;\n          if (newgain < 0.01) newgain = 0.01; // clamp\n          this.gains[i][d] = newgain; // store for next turn\n\n          // compute momentum step direction\n          var momval = this.iter < 250 ? 0.5 : 0.8;\n          var newsid = momval * sid - this.epsilon * newgain * grad[i][d];\n          this.ystep[i][d] = newsid; // remember the step we took\n\n          // step!\n          this.Y[i][d] += newsid;\n\n          ymean[d] += this.Y[i][d]; // accumulate mean so that we can center later\n        }\n      }\n\n      // reproject Y to be zero mean\n      for (var i = 0; i < N; i++) {\n        for (var d = 0; d < this.dim; d++) {\n          this.Y[i][d] -= ymean[d] / N;\n        }\n      }\n\n      //if(this.iter%100===0) console.log('iter ' + this.iter + ', cost: ' + cost);\n      return cost; // return current cost\n    }\n\n    // for debugging: gradient check\n\n  }, {\n    key: 'debugGrad',\n    value: function debugGrad() {\n      var N = this.N;\n\n      var cg = this.costGrad(this.Y); // evaluate gradient\n      var cost = cg.cost;\n      var grad = cg.grad;\n\n      var e = 1e-5;\n      for (var i = 0; i < N; i++) {\n        for (var d = 0; d < this.dim; d++) {\n          var yold = this.Y[i][d];\n\n          this.Y[i][d] = yold + e;\n          var cg0 = this.costGrad(this.Y);\n\n          this.Y[i][d] = yold - e;\n          var cg1 = this.costGrad(this.Y);\n\n          var analytic = grad[i][d];\n          var numerical = (cg0.cost - cg1.cost) / (2 * e);\n          console.log(i + ',' + d + ': gradcheck analytic: ' + analytic + ' vs. numerical: ' + numerical);\n\n          this.Y[i][d] = yold;\n        }\n      }\n    }\n\n    // return cost and gradient, given an arrangement\n\n  }, {\n    key: 'costGrad',\n    value: function costGrad(Y) {\n      var N = this.N;\n      var dim = this.dim; // dim of output space\n      var P = this.P;\n\n      var pmul = this.iter < 100 ? 4 : 1; // trick that helps with local optima\n\n      // compute current Q distribution, unnormalized first\n      var Qu = zeros(N * N);\n      var qsum = 0.0;\n      for (var i = 0; i < N; i++) {\n        for (var j = i + 1; j < N; j++) {\n          var dsum = 0.0;\n          for (var d = 0; d < dim; d++) {\n            var dhere = Y[i][d] - Y[j][d];\n            dsum += dhere * dhere;\n          }\n          var qu = 1.0 / (1.0 + dsum); // Student t-distribution\n          Qu[i * N + j] = qu;\n          Qu[j * N + i] = qu;\n          qsum += 2 * qu;\n        }\n      }\n      // normalize Q distribution to sum to 1\n      var NN = N * N;\n      var Q = zeros(NN);\n      for (var q = 0; q < NN; q++) {\n        Q[q] = Math.max(Qu[q] / qsum, 1e-100);\n      }\n\n      var cost = 0.0;\n      var grad = [];\n      for (var i = 0; i < N; i++) {\n        var gsum = new Array(dim); // init grad for point i\n        for (var d = 0; d < dim; d++) {\n          gsum[d] = 0.0;\n        }\n        for (var j = 0; j < N; j++) {\n          cost += -P[i * N + j] * Math.log(Q[i * N + j]); // accumulate cost (the non-constant portion at least...)\n          var premult = 4 * (pmul * P[i * N + j] - Q[i * N + j]) * Qu[i * N + j];\n          for (var d = 0; d < dim; d++) {\n            gsum[d] += premult * (Y[i][d] - Y[j][d]);\n          }\n        }\n        grad.push(gsum);\n      }\n\n      return { cost: cost, grad: grad };\n    }\n  }]);\n\n  return tSNE;\n}();\n\n;\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./lib/index.js\n// module id = 1\n// module chunks = 0"],"sourceRoot":""}